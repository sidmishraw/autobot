{"title":"A Verification Scheme For Data Aggregation in Data Mining","authorString":["Kilho Shin Carnegie Mellon CyLab Japan","yshin@cmuj.jp","Justin Zhan The Heinz School","Carnegie Mellon University justinzh@andrew.cmu.edu"],"content":"Abstract\nTo conduct data mining, we often need to collect data from various data owners. Privacy concerns may prevent the parties from directly sharing the data and some types of information about the data. To conduct data mining with- out compromising data privacy, we propose a verification scheme to ensure that the collected data follow the require- ments of data miners, which is one of the important issues in privacy-preserving data mining systems.\nKey Words: Data Collection, Data Mining, Verification, Cryptography.\n1 Introduction\nData mining is a powerful technology in extracting the hidden predictive information from large databases. Data mining tools predict future trends and behaviors, allow- ing businesses to make proactive, knowledge-driven deci- sions. The automated, prospective analysis offered by data mining move beyond the analysis of past events provided by retrospective tools typical of decision support systems. Data mining tools can answer business questions that tra- ditionally were too time consuming to resolve. They scour databases for hidden patterns, finding predictive informa- tion that experts may miss because it lies outside their ex- pectations.\nData mining techniques are the result of a long process of research and product development. Recent advances in data collection, data dissemination and related technologies have inaugurated a new era of research where existing data mining algorithms should be reconsidered from the point of view of privacy preservation.\nIn this paper, we would like to focus on data collection. In particular, we consider the following scenario: There are a number of data owners. Each of them retains or gener- ates as needed certain data sets. Those data sets are usually related to activities of an individual, and therefore may in- clude information that enables identification of the individ-\nual. On the other hand, a data aggregator collects such data sets, then forward them to data analysts.\nIn order to obtain correct analyzing results, a practi- cal model is that the data analysts inform data owners of their requirements regarding what information should be in- cluded in data sets. This indicates that the model should be equipped with some methods to make data owners honestly fulfill the requirements.\nTo address this problem, the paper assumes certain de- vices on hand at data owners’ points that guarantee the sup- port of the requirements and the accuracy of data sets on behalf of data analysts. As an implementation in the real world of such devices, referred to as Observers in the pa- per, we have IC-chip-based credit cards in mind. They not only have access to accurate personal information of cus- tomers but also provide secure environments to process data sets without dishonest interference by customers and others. Moreover, it is important to note that credit card companies are trustworthy from standpoints of customers and data an- alysts, and they certainly have motivation to play the role on behalf of data analysts. In consideration of these points, we strongly believe the framework with Observers for accurate data collection is realistic and feasible.\nHowever, from a privacy preservation point of view, the framework stated above would certainly raise problems. Since data sets may include information that would reveal the identities of customers or would allow trace of their ac- tivities, they must not be disclosed to anyone but data ana- lysts. Although this request can be supported by encrypting data sets, the encryption should be performed by Observers since, otherwise, customers have opportunities to submit in- accurate information. However, if Observers perform en- cryption, customers have serious concerns that Observers disclose sensitive information of customers exceeding their consents. Thus, it is critical to support this seemingly con- tradictory requirements. The main contribution of this paper is to propose a verification scheme to achieve such a goal.\n2007 IEEE International Conference on Granular Computing\n0-7695-3032-X/07 $25.00 © 2007 IEEE DOI 10.1109/GrC.2007.121\n374\n2007 IEEE International Conference on Granular Computing\n0-7695-3032-X/07 $25.00 © 2007 IEEE DOI 10.1109/GrC.2007.121\n374\n2 Framework and Fundamental Require- ments\n??? ??????\nIn the process of data collection, we observe three fun- damental players, namely data owners who retain or gener- ate as needed data sets to be collected, data analysts who draw some conclusion through analysis of collected data, and data aggregators who collect data sets on behalf of data analysts.\nFurther, we will classify data owners into two categories. One consists of privacy subjects (Subject), while the other consists of reporters (Reporter). A Subject (e.g. a customer) is an individual such that collected data sets may disclose his/her identity and/or may enable third parties to track him/her. On the other hand, a Reporter (e.g. a shop, restau- rant, virtual mall) provides information relating to Subject’s activities and/or interaction with the Reporter.\nThus, a data set comprises the part that a Subject pro- vides and the part that zero or more Reporter’s provide. The former part includes information that third parties can never get to know unless the Subject intentionally discloses it. In the rest of the paper, we refer to this part of data as non-observable private data. In contrast, the later part may include private information such that the Reporter obtains through observation of activities of the Subject. We refer to this part of data as observable private data. Table 2.1 shows examples of non-observable and observable private data.\nData type Examples\nNon-observable Name, Age, Day of Birth, Address, Telephone Number, Social Security Number, Passport Number, Nation- ality, Religion\nObservable Gender, Race, Height\nTable 1. Non-observable and observable pri- vate data\n??? ? ? ? ?? ?? ???? ??? ??? ???? ?? ??? Portal\nFrom Analyst’s standpoint, the most important require- ment for the data sets that it is going to collect must be their accuracy, in particular, the accuracy of non-observable information— non-observable information is such a kind of information that the Subject may be motivated to hide from Analyst’. Hence, it is likely that the Subject submits incorrect or totally different information as his/her non- observable information. To avoid such frauds by the Sub-\nject, and to support the Analyst’s requirement for the accu- racy of the data sets, this paper proposes the introduction of Portal.\nA Portal is a small portable device such that a Subject carries with himself/herself. A Portal stores Subject’s non- observable information in such a manner that even the Sub- ject cannot change it.\nConsidering a credit card as a candidate implementation of the Portal, the proposal is realistic. — A credit card is a very small portable device, and most of people retain at least one for each. Also, a credit card is used as a method of proof of cardholder’s identity in daily life.\nFrom security point of view, a smart-chip-equipped credit card [1] has plural desirable properties. First, it pro- vides fully access-controlled memories to protect stored confidential information. This functionality not only pro- tects cardholder’s secrets for cardholder’s sake, but also prevents a dishonest cardholder from tampering with data stored in it. Technically speaking, the smart-chip is equipped with a micro computer (for this reason, it is called smart), and the micro computer controls all the accesses from the outside to the data and the programs stored inside. Against attempts to bypass the access control by the micro computer, its tamper-resistant hardware implementation de- feats such attempts. In addition, the smart chip executes any confidential calculation (e.g. cryptographic calculation using secret keys) by itself, and hence confidential data con- sistently stay in the smart chip.\nA smart-chip-equipped credit card has advantages not only from security point of view but also from practice point of view. One of them is the derived information from the fact that credit card companies, namely the providers of credit cards, have been handling cardholders’ private infor- mation. In this sense, credit card companies have already acquired reasonable confidence in society to play the role of Aggregator. Consensus to use credit cards as the Portal would be created without great difficulties.\nTaking advantage of its security features, on input of ob- servable information from Reporter’s, a Portal combine the non-observable information stored in itself with the input observable information into a data set, and digitally signs it to guarantee the accuracy.\n??? ? ? ? ?? ??????? ??? ? ? ??????? ? ????\nFrom a privacy protection point of view, a Subject should be able to know the contents of data sets in advance that they are submitted to Analyst’s, and should retain the rights to reject requests to disclose his/her private information at will. Moreover, the Subject must require that his/her non- observable information should be disclosed only to the in- tended Analyst, and, in particular, should be hidden from\n375375\nObservable\nPrivate Info.\nAggregator\n(e.g. Credit Card Company)\nAnalyst\nReporter\n(e.g. Shop)\nPortal\n(e.g. Credit Card)\nNon-Observable\nPrivate Info.\nData Set\nData Set\nFigure 1. The Proposed Architecture\nReporter\nUser Device (Smart Chip)\nPortal\nSubject-Side Verifier\nTamper-Resistant Section\nUser-Dominant Section\nI/O\nObservable\nData Set\nGeneration\nNon-\nObservable\nContents\nInspection\nEncryption Signing\nVerification\nVerification\nSigning Aggregator\n1\n2\n3\n4\n5\n6a\n6b\n7\nFigure 2. An architecture of observers\nAggregatorand Reporter. This requirement for privacy pro- tection implies the following.\n1. The data sets must be encrypted so that only the in- tended Analyst can decrypt it.\n2. The Subject must be able to convince himself/herself that the encryption is executed properly.\nThe simplest way to fulfill the above is that the Subject en- crypts data sets using Analyst’s public key. However, this method apparently contradicts the requirement for the accu- racy of data sets stated in the previous section — a dishonest Subject may encrypt incorrect or fake data sets.\nThus, to fulfill the accuracy requirement, it is necessary that the encryption is executed by a Portal. On the other hand, to fulfill the privacy protection requirement, we need an appropriate verification scheme with which the Subject can inspect whether the Portal properly encrypts the data sets that the Subject intends to submit to the Analyst (e.g. whether the Portal did not encrypt information exceeding what the Subject consents to disclose, whether the encryp- tion is executed using Analyst’s public key). The objective\nand the main contribution of this paper is to present such a verification scheme.\n??? ??? ???????\nBased upon the arguments in the previous sections, Ta- ble 2.4 clarifies requirements from the viewpoints of the Subject, Reporter, Analyst and Aggregatorrespectively.\n?? !?? ????? ?? ???????? ??\nFig. 2 provides a big picture of our proposed architec- ture. A user device (e.g. a smart chip of a credit card) comprises two section. — One is the tamper-resistant sec- tion, while the other is the user-dominant section. In the tamper-resistant section, the non-observable information of the device-holder is stored, and the Portal program is in- stalled as well. Due to the tamper-resistant feature of the device, even the device-holder cannot tamper with the non- observable information or interfere in the processes of the Portal. On the other hand, the user-dominant section is laid under the total control by the device-user. — The device- user can store any kinds of data and install arbitrary pro- grams at will. The Subject-Side Verifier program, which controls all the inputs and the outputs of the Portal, and, in particular, inspects the contents of data sets as well as the outputs of the Portal, is presented in this section.\nFig. 2 also depicts the data flow and the procedures of the cooperation of the Portal the Subject-Side Verifier and the other entities.\nThe Information Flow in Fig. 2\n1. The Reporter inputs an instance of observable infor- mation into the Portal via the Subject-Side Verifier.\n2. The Portal retrieves the necessary part of the non- observable information stored in the tamper-resistant section.\n3. The Portal prepares a data set by combining the ob- servable information and the non-observable informa- tion, and then outputs the generated data set to the Subject-Side Verifier.\n4. The Subject-Side Verifier inspects whether its contents are appropriate. If possible, the Subject-Side Verifier may present the contents to the Subject for his/her con- sent using a displaying device (e.g. LCD). Unless the Subject-Side Verifier is satisfied with the contents, the Subject-Side Verifier discards the data set and aborts the process.\n5. Responded by the Subject-Side Verifier, the Portal en- crypts the data set using Analyst’s public key, and then signs the encrypted data set.\n376376\nPlayer Requirements\nSubject Only the non-observable information that the Subject consents to disclose shall be disclosed only to the Analyst to whom the Subject intends to disclose the non-observable information. In particular, the non-observable information shall be hidden from Aggregator’s and Reporter’s sights.\nReporter The observable information submitted to an Analyst shall be the same as what the Reporter intends to submit to the Analyst. In particular, the Subject shall not be able to tamper with the observable information.\nAnalyst A received data set shall be accurate in the following sense. — The non-observable information included in the data set shall be of the sorts that the Analyst requested and shall not be tampered with; The observable information included in the data set shall be the same as what the Reporter intends to submit to the Analyst.\nAggregator On receipt of a data set, and in advance of submitting it to the Analyst the Aggregator shall be able to verify that it is accurate in the sense stated in the previous row.\nTable 2. Requirements from the viewpoint of each player\n6. The encrypted and signed data set is sent to the Subject-Side Verifier, and the Subject-Side Verifier ex- ecutes the following.\n(a) The Subject-Side Verifier sends the received data to the Reporter. The Reporter verifies that the received data is right encryption of the same ob- servable information as the Reporter submitted in Step 1. If, and only if, the verification suc- ceeds, the Reporter signs the data and returns it to the Subject-Side Verifier.\n(b) The Subject-Side Verifier verifies that the re- ceived data is right encryption of exactly the same data set as the Subject-Side Verifier in- spected in Step 4. If the verification fails, the Subject-Side Verifier discards the data and aborts the process.\nThe Subject-Side Verifier outputs the encrypted and doubly-signed data set.\n7. Finally, the encrypted data set is sent to the Aggrega- tor, who collects data sets on behalf of Analyst.\n??\" ?????? ???# ???????\nThe requirements of the Analyst and the Aggregator will be supported by the procedures illustrated in the previous section. In fact, the Analyst and the Aggregator have only to verify the signatures of the Portal and the Reporter.\nTo support the requirements of the Subject and the Reporter, we need an additional verification scheme that should be used in Step 6b and Step 6a. The objective of the paper is to propose such a verification scheme. The diffi- culty in designing such a verification scheme is that neither the Subject nor the Reporter can decrypt the encrypted data set, because it is encrypted using Analyst’s public key.\nThe problem that we are struggling with in the subse- quent sections is to engineer a verification scheme such that the Subject and the Reporter can verify that an encrypted\ndata set is to encrypt the data that they expect without ac- cessing Analyst’s private key.\n3 Verifiable Entrusted Encryption\n??? $?%??????\nWe consider a public key encryption scheme ? with the following features.\n? The scheme involves three players, an entruster, a trustee and a recipient.\n? The trustee receives a clear text ? from the entruster, and encrypts it into ? using the recipient’s public key ? and the entrustee’s public key ??.\n? The entruster verifies that ? is a right encryption of ? using its private key.\n? The recipient decrypts ? into ? using its private key.\nDefinition 1 Let ? be an arbitrary message that an en- truster tries to make a trustee to encrypt. While ? is right encryption of? with respect to? and??, let ?? be arbitrary data such that it is not right encryption of ?. Furthermore, let ?? be right encryption of ? but using the public key of a different entruster. If ? satisfies the conditions of Com- pleteness, Soundness and Secrecy, it is called a verifiable entrusted encryption scheme.\n? Completeness: The entruster accepts ?.\n? Soundness: The entruster accepts ?? only with a negli- gible probability.\n? Secrecy: The entruster distinguishes between ?? and ?? only with a negligible advantage.\nIn the subsequent clauses, we propose an instance of the verifiable entrusted encryption scheme by presenting its key generation, encryption, decryption and verification steps separately. Further, we will give a proof for its com- pleteness, soundness and secrecy.\n377377\n??? \u0026?? \u0027?????????\nThe public key pairs of the recipient and the entruster are generated using a common cyclic group ?. In the remainder of this paper, the operation of ? is denoted by the additive operator ? for simplicity. Moreover, we assume the follow- ing.\n? ? ? ?? ? for a prime number ?.\n? ? is a fixed generator of ?.\n? Decision Diffie-Hellman problems (DDHP) are com- putationally intractable over ?. Given a quadruple ??? ?? ? ? ? ??, the corresponding DDHP is the problem to determine whether ? ? ?? and ? ? hold for some ? ? ??? ??.\nThe public key pair of the recipient is a pair ??? ?? such that ? ? ??. The recipient randomly selects ? ? ??? ??, and submits ? as its public key.\nOn the other hand, the public key pair of the entruster is a pair ???? ? ? ??? such that ?? ? ????. The recipient randomly selects ? ? ?? ? ??? ???, and submits ?? as its public key.\nNote that ?? is dependent on ?, and, therefore, the en- truster has to prepare as many public key pairs as the recip- ients that it likes to communicate.\n??? (?????????\nThe scheme that we propose in this paper is based on the ElGamal public key encryption. The trustee encrypts a clear text ? as follows.\n1. Select a random ? ? ??? ??.\n2. Calculate ? ? ??, ? ? ??, and ? ? ?? ??.\n3. Output the triplet ????? ?? as the cipher text.\n??? $?????????\nSince ??? ?? is in accordance with the ordinary ElGamal public key encryption, the recipient who retains the private key ? corresponding to the public key ? can decrypts ? as follows.\n? ? ?? ?? ? ?\n?? )???%??????\nThe entruster doesn’t know the private key ?, which is a critical component to decrypt ?. However, by verifying that the following equality holds, it can verify the correctness of ????? ?? without decrypting ?.\n? ? ? ? ?????? (1)\n??\" ????? ?? ??? ????\nWe will prove the completeness, soundness and secrecy of the proposed scheme.\nThe completeness immediately follows from the defini- tion.\nThe soundness is proved as follows. When ?, ? and ? satisfy ? ? ??, ?? ? ?? and ? ? ? ? ??, the fact that the entruster successfully verifies (1) indicates that the equalities of (2) and (3) hold at the same time.\n? ? ? ?? (2)\n? ? ? ? ?? (3)\nIf ? ?? ??, only a single instance of ? ? ?? satisfies (3) and (2). Therefore, the probability that the trustee, who does not know the value of or ?, can present ? such that (3) holds is only ?\n?? .\nLastly, we will prove the secrecy of the proposed scheme. While ????? ??? ?? ? ?? is a DDH quadruple but ????? ??? ?? ? ??. If the entruster distinguishes between them with a significant advantage, it can also solve DDHP’s.\n4 Solving the Problem\nTo solve the problem stated in Section 2.6, it suffices that the Portal plays the role of the trustee, and encrypts the non-observable information and observable information in accordance with the verifiable entrusted encryption scheme presented in the previous section.\nIn the following, let ? and Æ denote the non-observable information and the observable information, respectively. The Portal uses Analyst’s public key ?, Subject’s public key ?? and Reporter’s public key ???. In Step 5, the Por- tal encrypts the non-observable information and observable information as follows.\n1. Generate random ?? ?? ? ??? ?? and let ? and ?? be ?? and ???.\n2. Encrypt Æ and ? into ??? ?? and ???? ???\n? ? ??? Æ ?? ? ???? ?\n3. Calculate ?, ?? and ?? as follows.\n? ? ???? ? ? ? ????? ?? ? ? ???\n4. The cipher text for Æ is ??? ????? ??, while that for ? is ???? ??? ???.\nIn Step 6b of the information flow architecture, the Subject-Side Verifier inspects ????? ?? and ???? ??? ??? based on the knowledge of Æ and ? informed in Step 4. In the same way, in Step 6a, the Reporter inspects ? ????? ?? based on the knowledge of Æ that it submitted.\n378378\n5 Discussion\nTo protect actual data from being disclosed, one ap- proach is to alter the data in a way that actual individual data values cannot be recovered, while certain computations can still be applied to the data. Due to the fact that the actual data are not provided for the mining, the privacy of data is preserved. This is the core idea of randomization-based techniques. Randomization approaches were first proposed by Agrawal and Srikant [2] to solve the privacy-preserving data mining problem. Specifically, they addressed the fol- lowing question. Since the primary task in data mining is the development of models about aggregated data, can they develop accurate models without access to precise in- formation in individual data records? The underlying as- sumption is that a person will be willing to selectively di- vulge information in exchange of useful information that such a model can provide. Du and Zhan [3] proposed a technique for building decision trees using randomized re- sponse techniques which were developed in the statistics community for the purpose of protecting surveyees pri- vacy. The randomization-based methods have the bene- fits of efficiency. However, the drawbacks are that post- randomization data mining results are only an approxima- tion of pre-randomization results. Encryption is a well- known technique for preserving the confidentiality of sen- sitive information. Comparing with other techniques de- scribed, a strong encryption scheme can be more effective in protecting the data privacy. An encryption system nor- mally requires that the encrypted data should be decrypted before making any operations on it. For example, if the value is hidden by a randomization-based technique, the original value will be disclosed with certain probability. If the value is encrypted using a semantic secure encryption scheme [4], the encrypted value provide no help for attacker to find the original value. One of the schemes is the homo- morphic encryption which was originally proposed in [5] with the aim of allowing certain computations performed on encrypted data without preliminary decryption operations. To date, there are many such systems. Homomorphic en- cryption is a very powerful cryptographic tool and has been applied in several research areas such as electronic voting, on-line auction, etc. [6] is based on homomorphic encryp- tion where Wright and Yang applied homomorphic encryp- tion to the Bayesian networks induction for the case of two parties. Zhan et. al. [7] proposed a cryptographic approach to tackle collaborative association rule mining among mul- tiple parties.\nTo our best knowledge, most of the previous works deal- ing with data mining computation lack of works coping with verification in data aggregation which is one of critical steps in data mining systems. In this paper, we have proposed a verification scheme for data aggradation in data mining pro-\ncess. We have shown that our scheme guarantees that data analysts can verify whether the collected data follow the re- quirements without actually disclosing the original data. In the future, we would like to extend the work to cope with the verification of other steps in data mining systems.\nReferences\n[1] EMVCo, EMV Integrated Circuit Card Specifi- cation for Payment Systems — Common Pay- ment Application Specification, December, 2005, http://www.emvco.com\n[2] R. Agrawal and R. Srikant, Privacy-preserving data mining, Proceedings of the ACM SIGMOD Confer- ence on Management of Data, 439–450,May, 2000, Dallas, Texas\n[3] W. Du and Z. Zhan, Using Randomized Response Techniques for Privacy-Preserving Data Mining, Pro- ceedings of The 9th ACM SIGKDD International Conference on Knowledge Discovery and Data Min- ing. Washington, DC, USA. August 24 - 27, 2003\n[4] P. Paillier, Public-key cryptosystems based on com- posite degree residuosity classes, Advances in Cryp- tography - EUROCRYPT ’99, pp 223-238, Prague, Czech Republic,1999\n[5] R. Rivest and L. Adleman and M. Dertouzos, On data banks and privacy homomorphisms, Foundations of Secure Computation, eds. R. A. DeMillo et al., Aca- demic Press, pp. 169-179, 1978\n[6] R. Wright and Z. Yang, Privacy-Preserving Bayesian Network Structure Computation on Distributed Het- erogeneous Data, Proceedings of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD),2004\n[7] J. Zhan and S. Matwin and L. Chang, Privacy- Preserving Collaborative Association Rule Mining, 19th Annual IFIP WG 11.3 Working Conference on Data and Applications Security, Nathan Hale Inn, Uni- versity of Connecticut, Storrs, CT, U.S.A., August 7- 10, 2005\n379379"}